/*--------------------------------------------------------------------------------
  DATA TO INSIGHTS V3

  #4 in the simple core demo flow.
  Run this in your demo account.

  This script loads the TRIPS table from staged CSV files. It shows vertical
  scalability when changing the warehouse size, and then shows how Snowflake
  gives performance without needing to tune the data.

  Author:   Alan Eldridge
  Updated:  10 Aug 2020 - aeldridge - V3.1

--------------------------------------------------------------------------------*/

/*--------------------------------------------------------------------------------
  In this chapter you will see how you can:
	- combine structured and semi-structured data to answer business questions
  - use Snowflake's geospatial capabilities
  - use Snowflake's worksheets and dashboards for an analytic user experience
--------------------------------------------------------------------------------*/

-- set the context
use role dba_citibike;
use warehouse load_wh;
call citibike.utils.set_context('load_wh', 'medium', 'citibike.demo');


-- so this seems like a really simple query (and it runs very quickly)...
select * from trips_stations_weather_vw limit 200;


/*--------------------------------------------------------------------------------
  But - think about what just happened for that query...

  100M+ structured trips records
  ... dynamically masked based on user role,
  ... joined with ~100M weather records in native JSON format
  ... augmented by neighborhood spatial data
  ... transparently tracking changes we make to the table

  How long would all this take you today with your current systems?

  Let's run some exploratory queries to test our data model...
--------------------------------------------------------------------------------*/

-- in hourly groups for a specific starting station, how many trips were taken,
-- how long did they last, and how far did they ride?
select date_trunc(hour, starttime) hour,
    count(*) num_trips,
    avg(datediff("minute", starttime, stoptime))::integer avg_duration_mins,
    truncate(avg(st_distance(start_geo, end_geo))/1000,1) avg_distance_kms
  from trips_stations_weather_vw
  where start_station = 'Central Park S & 6 Ave'
  group by 1
  order by 2 desc;


-- what are the top 20 most popular cycle routes this year and how long do they take?
select
    start_station, end_station,
    count(*) num_trips,
    avg(datediff("minute", starttime, stoptime))::integer avg_duration_mins,
    truncate(avg(st_distance(start_geo, end_geo))/1000,1) avg_distance_kms
  from trips_stations_weather_vw
  where year(starttime) = 2020
  group by 1, 2
  order by 3 desc;


/*--------------------------------------------------------------------------------
  Both of these queries are non-trivial:
    - temporal and geospatial functions
    - aggregations
    - parsing semi-structured data
    - joining across multiple tables

  And they just work... no tuning, no indexing, no distribution keys, no clustering.
  With fast response times on one of our smaller warehouse configurations.

  This is our philosophy... just focus on using the data, not wrestling with it.
--------------------------------------------------------------------------------*/

-- there seems to be a buch of NULL data from retired stations though...
-- let's clean it up
delete from trips
  where start_station_id in (
      select start_station_id from trips_stations_weather_vw where start_station is null)
    or end_station_id in (
      select end_station_id from trips_stations_weather_vw where end_station is null);

select count(*) from trips_stations_weather_vw;


/*--------------------------------------------------------------------------------
  Let's let Jane explore it in more detail... using her preferred tools:
    - Snowsight
    - Tableau
--------------------------------------------------------------------------------*/
